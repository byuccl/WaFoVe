## How are the VCD files compared?
To understand how the files are compared, it's important to understand how VCD files are organized. When a testbench is created, the testbench initializes all signals to 0, and then at specific times will set inputs to a randomized value. The VCD file, similarly, initializes all signals to 0, and then will show whenever a signal's state changes. So, the format commonly follows that signals are initialzed, then the VCD file will show the time at the next state change, and then the given signal that changes state. The signals are not represented with their actual names, rather, they are encoded with symbols such as `a`, `$`, and `a0`. Because the two designs being compared are not coded the same way, their VCD files often differ in symbol names and in the order that state changes are represented at a given time. As a result, a simple diff checker between the two is not enough. So, WaFoVe uses a specially created algorithm to keep track of each signals associated symbol and it's state at every given time of operation. Then, once this information has been gathered on both VCD files, a loop is run that confirms that every IO is the same at the same time for both designs. If it is proven that they are equivalent, then the simulations are considered to have produced the same results. All of this functionality can be viewed in the `parse_diff.py`.

## Why are the VCD files not compared using a third-party software?
With every third-party software I've researched, none were able to adequately analyze how effective the VCD files actually were. For instance, `vcddiff` provided only minimal functions for testing and could not provide adequate information regarding which signals were not equivalent and why. So, I designed an algorithm that can track the state of each signal at a given time and then compare between the two files at the end. 

## How are internal signals tracked in VCD files?
All that is checked for equivalence with VCD files are the IOs. This is because two designs, in spite of having the same functionality, can still have differing internal signals. However, `parse_diff.py` will still watch the state of all internal signals so that the effectivness of a given testbench can be analyzed. While not ideal, most testbenches will not reach 100% efficiency because some designs require specific timing and input combinations for internal signals and outputs to raise properly. The likelihood of these cases occuring when a psudo-random algorithm is creating testbenches is very low. To mitigate this issue, a seed can be chosen for the random algorithm and the effectiveness of the particular simulation is provided. This allows for the user to continually test the design until they reach an effectiveness that they are satisfied with.